{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bca41ed-dc13-4c30-b90a-5dec82ee8c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         Allergist       1.00      1.00      1.00        48\n",
      "      Cardiologist       1.00      1.00      1.00        48\n",
      "       Common Cold       1.00      1.00      1.00        23\n",
      "     Dermatologist       1.00      1.00      1.00       110\n",
      "   Endocrinologist       1.00      1.00      1.00        92\n",
      "Gastroenterologist       1.00      1.00      1.00       118\n",
      "      Gynecologist       1.00      1.00      1.00        26\n",
      "      Hepatologist       1.00      1.00      1.00       179\n",
      " Internal Medicine       1.00      1.00      1.00        73\n",
      "       Neurologist       1.00      1.00      1.00        72\n",
      "   Osteoarthristis       1.00      1.00      1.00        22\n",
      "       Osteopathic       1.00      1.00      1.00        30\n",
      "  Otolaryngologist       1.00      1.00      1.00        18\n",
      "      Pediatrician       1.00      1.00      1.00        19\n",
      "      Phlebologist       1.00      1.00      1.00        22\n",
      "     Pulmonologist       1.00      1.00      1.00        61\n",
      "    Rheumatologist       1.00      1.00      1.00        23\n",
      "\n",
      "          accuracy                           1.00       984\n",
      "         macro avg       1.00      1.00      1.00       984\n",
      "      weighted avg       1.00      1.00      1.00       984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Load and Clean Data\n",
    "df = pd.read_excel('dataset/Specialist.xlsx')\n",
    "df.columns = df.columns.str.strip()  # Clean column names\n",
    "df['Disease'] = df['Disease'].str.strip().replace({\n",
    "    'Dermatologists': 'Dermatologist',\n",
    "    'Rheumatologists': 'Rheumatologist',\n",
    "    'Internal Medcine': 'Internal Medicine'\n",
    "})\n",
    "\n",
    "# 2. Prepare Features and Target\n",
    "X = df.drop(columns=['Unnamed: 0', 'Disease'], errors='ignore')\n",
    "y = df['Disease']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train Model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict and Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Function to predict specialist for new symptoms\n",
    "def predict_specialist(symptoms_list):\n",
    "    # symptoms_list: list of strings matching column names\n",
    "    input_data = pd.DataFrame(0, index=[0], columns=X.columns)\n",
    "    for s in symptoms_list:\n",
    "        if s in input_data.columns:\n",
    "            input_data[s] = 1\n",
    "    pred_idx = model.predict(input_data)[0]\n",
    "    return le.inverse_transform([pred_idx])[0]\n",
    "\n",
    "# Example Usage:\n",
    "# print(predict_specialist(['itching', 'skin_rash']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "751f17ed-463f-4d63-acbe-eba2a98eb84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neurologist\n"
     ]
    }
   ],
   "source": [
    "print(predict_specialist(['headache', 'cough', 'mild_fever']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1538b587-686f-4396-bd66-947d444ac9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1. Load the dataset to get the vocabulary\n",
    "df = pd.read_excel('dataset/Specialist.xlsx')\n",
    "df.columns = df.columns.str.strip()\n",
    "# Extract only the symptom column names\n",
    "dataset_symptoms = [col for col in df.columns if col not in ['Unnamed: 0', 'Disease']]\n",
    "\n",
    "# 2. Pre-processing: Create a human-readable version of the symptoms\n",
    "# (e.g., 'skin_rash' becomes 'skin rash')\n",
    "clean_symptoms = [s.replace('_', ' ') for s in dataset_symptoms]\n",
    "\n",
    "# 3. Initialize the NLP Model (TF-IDF with Character N-Grams)\n",
    "# Using char n-grams allows matching 'itchy' to 'itching' or 'pained' to 'pain'\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4)).fit(clean_symptoms)\n",
    "symptom_vectors = vectorizer.transform(clean_symptoms)\n",
    "\n",
    "def nlp_to_dataset_symptoms(user_input, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Converts user language to a list of dataset-compliant symptom names.\n",
    "    \"\"\"\n",
    "    user_input = user_input.lower()\n",
    "    \n",
    "    # Split the user input into logical segments\n",
    "    # Splitting by common conjunctions helps extract multiple symptoms\n",
    "    segments = re.split(r'[,.!?]| and | with | having | including | plus ', user_input)\n",
    "    segments = [s.strip() for s in segments if len(s.strip()) > 2]\n",
    "    \n",
    "    found_symptoms = []\n",
    "    \n",
    "    for seg in segments:\n",
    "        # Calculate similarity between this segment and all dataset symptoms\n",
    "        seg_vec = vectorizer.transform([seg])\n",
    "        scores = cosine_similarity(seg_vec, symptom_vectors).flatten()\n",
    "        \n",
    "        # Get indices of matches that pass the similarity threshold\n",
    "        # We take the best match for each segment of the sentence\n",
    "        if np.max(scores) > threshold:\n",
    "            best_match_idx = np.argmax(scores)\n",
    "            found_symptoms.append(dataset_symptoms[best_match_idx])\n",
    "            \n",
    "    # Deduplicate and return\n",
    "    return list(set(found_symptoms))\n",
    "\n",
    "\n",
    "\n",
    "# Now you can pass 'extracted' to your specialist prediction model:\n",
    "# predicted_specialist = model.predict(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa93a16b-687c-4ba7-831a-226a64fb131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User said: 'I have fever and  cough with mild headache '\n",
      "Detected Symptoms: ['headache', 'cough', 'mild_fever']\n"
     ]
    }
   ],
   "source": [
    "user_sentence = \"I have fever and  cough with mild headache \"\n",
    "extracted = nlp_to_dataset_symptoms(user_sentence)\n",
    "\n",
    "print(f\"User said: '{user_sentence}'\")\n",
    "print(f\"Detected Symptoms: {extracted}\")\n",
    "# spec=predict_specialist(extracted)\n",
    "# print(f\"recomended specialist: {spec}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0cb080-bc08-4fbd-ac39-a05cd731f73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_columns.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"model.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")\n",
    "joblib.dump(X.columns.tolist(), \"feature_columns.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f8cb6e-5f58-4d8f-98ad-0f290e7b10a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import requests\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# Load saved files\n",
    "model = joblib.load(\"model.pkl\")\n",
    "le = joblib.load(\"label_encoder.pkl\")\n",
    "feature_columns = joblib.load(\"feature_columns.pkl\")\n",
    "\n",
    "# Prepare NLP vocabulary\n",
    "clean_symptoms = [s.replace('_', ' ') for s in feature_columns]\n",
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4)).fit(clean_symptoms)\n",
    "symptom_vectors = vectorizer.transform(clean_symptoms)\n",
    "\n",
    "\n",
    "def nlp_to_dataset_symptoms(user_input, threshold=0.3):\n",
    "    user_input = user_input.lower()\n",
    "    segments = re.split(r'[,.!?]| and | with | having | including | plus ', user_input)\n",
    "    segments = [s.strip() for s in segments if len(s.strip()) > 2]\n",
    "\n",
    "    found_symptoms = []\n",
    "\n",
    "    for seg in segments:\n",
    "        seg_vec = vectorizer.transform([seg])\n",
    "        scores = cosine_similarity(seg_vec, symptom_vectors).flatten()\n",
    "\n",
    "        if np.max(scores) > threshold:\n",
    "            best_match_idx = np.argmax(scores)\n",
    "            found_symptoms.append(feature_columns[best_match_idx])\n",
    "\n",
    "    return list(set(found_symptoms))\n",
    "\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: dict):\n",
    "    user_sentence = data[\"sentence\"]\n",
    "\n",
    "    extracted = nlp_to_dataset_symptoms(user_sentence)\n",
    "\n",
    "    input_data = pd.DataFrame(0, index=[0], columns=feature_columns)\n",
    "    for s in extracted:\n",
    "        input_data[s] = 1\n",
    "\n",
    "    pred_idx = model.predict(input_data)[0]\n",
    "    specialist = le.inverse_transform([pred_idx])[0]\n",
    "\n",
    "    return {\n",
    "        \"detected_symptoms\": extracted,\n",
    "        \"recommended_specialist\": specialist\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1a63a-75cb-442e-b0e7-7a27f3ab40b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
